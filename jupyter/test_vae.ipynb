{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './../')\n",
    "import sdss_psf\n",
    "import simulated_datasets_lib\n",
    "import starnet_vae_lib\n",
    "import inv_kl_objective_lib as inv_kl_objective_lib\n",
    "\n",
    "import kl_objective_lib \n",
    "\n",
    "import utils\n",
    "\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('torch version: ', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load PSF\n",
    "psf_fit_file = '../../celeste_net/sdss_stage_dir/3900/6/269/psField-003900-6-0269.fit'\n",
    "print('psf file: \\n', psf_fit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(43534)\n",
    "_ = torch.manual_seed(24534)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parameters\n",
    "with open('../data/default_star_parameters.json', 'r') as fp:\n",
    "    data_params = json.load(fp)\n",
    "\n",
    "\n",
    "data_params['f_max'] = 1e5\n",
    "\n",
    "print(data_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_stars = data_params['max_stars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 4\n",
    "\n",
    "star_dataset = \\\n",
    "    simulated_datasets_lib.load_dataset_from_params(psf_fit_file,\n",
    "                            data_params,\n",
    "                            n_images = n_images,\n",
    "                            add_noise = True)\n",
    "\n",
    "num_unlabeled = star_dataset.fluxes.shape[0]\n",
    "print('num unlabeled', num_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loader \n",
    "batchsize = n_images\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "                 dataset=star_dataset,\n",
    "                 batch_size=batchsize,\n",
    "                 shuffle=False)\n",
    "\n",
    "loader.dataset.set_params_and_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(loader):\n",
    "    true_full_fluxes = data['fluxes']\n",
    "    true_full_locs = data['locs']\n",
    "    full_images = data['image']\n",
    "    full_backgrounds = data['background']\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4): \n",
    "    plt.matshow(full_images[i, 0, :, :] - full_backgrounds[i, 0, :, :])\n",
    "    plt.colorbar()\n",
    "    print((full_images[i, 0, :, :] - full_backgrounds[i, 0, :, :]).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_encoder = starnet_vae_lib.StarEncoder(full_slen = data_params['slen'],\n",
    "                                           stamp_slen = 9,\n",
    "                                           step = 2,\n",
    "                                           edge_padding = 3,\n",
    "                                           n_bands = 1,\n",
    "                                           max_detections = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check my extraction of subimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stamps, subimage_locs, subimage_fluxes, n_stars, is_on_array = \\\n",
    "    star_encoder.get_image_stamps(full_images, true_full_locs, true_full_fluxes, trim_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_stars, bins = np.arange(min(n_stars), max(n_stars) + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check these two quantities match \n",
    "is_on_array2 = utils.get_is_on_from_n_stars(n_stars, max(n_stars))\n",
    "assert torch.all(is_on_array2 == is_on_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check total number of stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This asserts that we indeed have a covering of stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_images):\n",
    "    _true_locs = true_full_locs[i] * (data_params['slen'] - 1) \n",
    "\n",
    "    pad = np.float(star_encoder.edge_padding)\n",
    "\n",
    "    n_true_stars = torch.sum((_true_locs[:, 0] > pad) & (_true_locs[:, 1] > pad) & \\\n",
    "                (_true_locs[:, 0] < (data_params['slen'] - pad - 1))& \\\n",
    "                (_true_locs[:, 1] < (data_params['slen']  - pad - 1)))\n",
    "    \n",
    "    n_stamps_per_batch = star_encoder.tile_coords.shape[0]\n",
    "    \n",
    "    # check subimage n_stars add up\n",
    "    assert torch.sum(n_stars[(i * n_stamps_per_batch):((i + 1) * n_stamps_per_batch)]) == n_true_stars\n",
    "    \n",
    "    # check number of nonzero fluxes add up\n",
    "    assert (subimage_fluxes[(i * n_stamps_per_batch):((i + 1) * n_stamps_per_batch)] > 0).sum() == n_true_stars\n",
    "    \n",
    "    # check number of nonzero locs add up\n",
    "    assert (subimage_locs[(i * n_stamps_per_batch):((i + 1) * n_stamps_per_batch)] > 0).sum() == \\\n",
    "                (n_true_stars * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assert we have correct number and pattern of nonzero entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all((subimage_locs * is_on_array.unsqueeze(2).float()) == subimage_locs)\n",
    "assert torch.all((subimage_fluxes * is_on_array.float()) == subimage_fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all((subimage_locs != 0).view(subimage_locs.shape[0], -1).float().sum(1) == \\\n",
    "                     n_stars.float() * 2)\n",
    "assert torch.all((subimage_fluxes != 0).float().sum(1) == n_stars.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is what the NN sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10): \n",
    "    f, axarr = plt.subplots(1, 3, figsize=(12, 6))\n",
    "    indx = int(np.random.choice(image_stamps.shape[0], 1))\n",
    "    \n",
    "    which_nonzero = is_on_array[indx].type(torch.bool)\n",
    "    \n",
    "    # Plot my image patch. \n",
    "    im1 = axarr[0].matshow(image_stamps[indx].squeeze())\n",
    "    patch_slen = star_encoder.stamp_slen - 2 * star_encoder.edge_padding\n",
    "    axarr[0].scatter(subimage_locs[indx, which_nonzero, 1] * (patch_slen - 1) + star_encoder.edge_padding, \n",
    "                    subimage_locs[indx, which_nonzero, 0] * (patch_slen - 1) + star_encoder.edge_padding, \n",
    "                    color = 'b')\n",
    "    \n",
    "    # plot subset of full image. They should match. \n",
    "    x0 = star_encoder.tile_coords[indx % star_encoder.tile_coords.shape[0], 0]\n",
    "    x1 = star_encoder.tile_coords[indx % star_encoder.tile_coords.shape[0], 1]\n",
    "\n",
    "    image_full_i = full_images[indx // star_encoder.tile_coords.shape[0]]\n",
    "    image_patch_i = image_full_i.squeeze()[x0:(x0 + star_encoder.stamp_slen), \n",
    "                                         x1:(x1 + star_encoder.stamp_slen)]\n",
    "    axarr[1].matshow(image_patch_i)\n",
    "    \n",
    "    assert torch.all((image_stamps[indx].squeeze() - image_patch_i) == 0)\n",
    "    \n",
    "    locs_i = true_full_locs[indx // star_encoder.tile_coords.shape[0]] * (star_encoder.full_slen - 1)\n",
    "    \n",
    "    which_locs = ((locs_i[:, 0] > x0.float()) & (locs_i[:, 1] > x1.float())) & \\\n",
    "                    (locs_i[:, 0] < (x0 + star_encoder.stamp_slen).float() - 1) & \\\n",
    "                    (locs_i[:, 1] < (x1 + star_encoder.stamp_slen).float() - 1)\n",
    "            \n",
    "    axarr[1].scatter(locs_i[which_locs, 1] - x1, \n",
    "               locs_i[which_locs, 0] - x0, \n",
    "               marker = 'o', color = 'b')\n",
    "    \n",
    "    axarr[1].axvline(x=star_encoder.edge_padding, color = 'r')\n",
    "    axarr[1].axvline(x=star_encoder.stamp_slen - star_encoder.edge_padding - 1, color = 'r')\n",
    "    axarr[1].axhline(y=star_encoder.edge_padding, color = 'r')\n",
    "    axarr[1].axhline(y=star_encoder.stamp_slen - star_encoder.edge_padding - 1, color = 'r')\n",
    "    \n",
    "        \n",
    "    axarr[0].axvline(x=star_encoder.edge_padding, color = 'r')\n",
    "    axarr[0].axvline(x=star_encoder.stamp_slen - star_encoder.edge_padding - 1, color = 'r')\n",
    "    axarr[0].axhline(y=star_encoder.edge_padding, color = 'r')\n",
    "    axarr[0].axhline(y=star_encoder.stamp_slen - star_encoder.edge_padding - 1, color = 'r')\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    # experimentation\n",
    "#     foo = skimage.exposure.equalize_hist(image_full_i.squeeze().numpy())\n",
    "#     im2 = axarr[2].matshow(foo[x0:(x0 + star_encoder.stamp_slen), \n",
    "#                         x1:(x1 + star_encoder.stamp_slen)])\n",
    "#     f.colorbar(im2, ax = axarr[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check my output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stamps, subimage_locs, subimage_fluxes, n_stars, is_on_array = \\\n",
    "    star_encoder.get_image_stamps(full_images, true_full_locs, true_full_fluxes, \n",
    "                                  trim_images=False, clip_max_stars = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_stamps = full_backgrounds.mean() # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_loc_mean, logit_loc_log_var, \\\n",
    "    log_flux_mean, log_flux_log_var, log_probs = \\\n",
    "        star_encoder(image_stamps, background_stamps, n_stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check we have the correct number (and pattern) of nonzero entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all((logit_loc_mean * is_on_array.unsqueeze(2).float()) == logit_loc_mean)\n",
    "assert torch.all((logit_loc_log_var * is_on_array.unsqueeze(2).float()) == logit_loc_log_var)\n",
    "assert torch.all((log_flux_mean * is_on_array.float()) == log_flux_mean)\n",
    "assert torch.all((log_flux_log_var * is_on_array.float()) == log_flux_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all((logit_loc_mean != 0).view(logit_loc_mean.shape[0], -1).float().sum(1) == \\\n",
    "                     n_stars.float() * 2)\n",
    "assert torch.all((logit_loc_log_var != 0).view(logit_loc_log_var.shape[0], -1).float().sum(1) == \\\n",
    "                     n_stars.float() * 2)\n",
    "\n",
    "assert torch.all((log_flux_mean != 0).float().sum(1) == n_stars.float())\n",
    "assert torch.all((log_flux_log_var != 0).float().sum(1) == n_stars.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = inv_kl_objective_lib.get_fluxes_logprob_all_combs(subimage_fluxes, log_flux_mean, log_flux_log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(5, 3).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(subimage_fluxes + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = subimage_fluxes[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo[(0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_flux_mean = torch.tensor([0.3, 0.2])\n",
    "# print(_log_flux_mean)\n",
    "# print(_log_flux_mean[(0, 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_log_flux_mean[(0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check my recon loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import image_utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "recon_means, recon_loss = kl_objective_lib.get_recon_loss(full_images, full_backgrounds,\n",
    "                                                            subimage_locs,\n",
    "                                                            subimage_fluxes.contiguous(),\n",
    "                                                            star_encoder.tile_coords,\n",
    "                                                            star_encoder.stamp_slen,\n",
    "                                                            star_encoder.edge_padding,\n",
    "                                                            star_dataset.simulator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(batchsize): \n",
    "    f, axarr = plt.subplots(1, 4, figsize=(16, 3))\n",
    "\n",
    "    im0 = axarr[0].matshow(full_images[i].squeeze()); \n",
    "    f.colorbar(im0, ax=axarr[0])\n",
    "    \n",
    "    im1 = axarr[1].matshow(recon_means[i].squeeze())\n",
    "    f.colorbar(im1, ax=axarr[1])\n",
    "    \n",
    "    im2 = axarr[2].matshow(full_images[i].squeeze() - recon_means[i].squeeze())\n",
    "    f.colorbar(im2, ax=axarr[2])\n",
    "    \n",
    "    pad = 10\n",
    "    im3 = axarr[3].matshow((full_images[i].squeeze() - recon_means[i].squeeze())[pad:-pad, pad:-pad])\n",
    "    f.colorbar(im3, ax=axarr[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.argmax(log_probs, 1).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from KL_objective_lib import sample_normal, get_recon_loss\n",
    "from simulated_datasets_lib import get_is_on_from_n_stars"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_kl_prior_term(mean, logvar):\n",
    "    # ADD this to the LOSS\n",
    "    return - 0.5 * (1 + logvar - mean.pow(2) - logvar.exp())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_loss_cond_nstars(star_encoder, full_images, full_backgrounds, h, n_stars): \n",
    "    is_on_array = get_is_on_from_n_stars(n_stars, star_encoder.max_detections)\n",
    "    \n",
    "    # get parameters \n",
    "    logit_loc_mean, logit_loc_logvar, \\\n",
    "            log_flux_mean, log_flux_logvar = \\\n",
    "                star_encoder._get_params_from_last_hidden_layer(h, n_stars)\n",
    "    \n",
    "    # sample locations \n",
    "    subimage_locs_sampled = torch.sigmoid(sample_normal(logit_loc_mean, logit_loc_log_var)) * \\\n",
    "                                            is_on_array.unsqueeze(2).float()\n",
    "\n",
    "    # sample fluxes\n",
    "    subimage_fluxes_sampled = torch.exp(sample_normal(log_flux_mean, log_flux_log_var)) * \\\n",
    "                        is_on_array.float()\n",
    "        \n",
    "    # get reconstruction loss\n",
    "    _, recon_loss = get_recon_loss(full_images, full_backgrounds, \n",
    "                                   subimage_locs_sampled, subimage_fluxes_sampled,\n",
    "                                   star_encoder.tile_coords, \n",
    "                                   star_encoder.stamp_slen, \n",
    "                                   star_encoder.edge_padding, \n",
    "                                   star_dataset.simulator)\n",
    "    \n",
    "    # get kl prior term: this is for each subimage\n",
    "    locs_kl_prior_term = get_kl_prior_term(logit_loc_mean, logit_loc_log_var).sum(2).sum(1)\n",
    "    fluxes_kl_prior_term = get_kl_prior_term(log_flux_mean, log_flux_log_var).sum(1)\n",
    "    \n",
    "    return recon_loss + locs_kl_prior_term.view(full_images.shape[0], -1).sum(1) + \\\n",
    "                            fluxes_kl_prior_term.view(full_images.shape[0], -1).sum(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h = star_encoder._forward_to_last_hidden(image_stamps, background_stamps)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs = star_encoder._get_logprobs_from_last_hidden_layer(h)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "loss = \\\n",
    "    get_loss_cond_nstars(star_encoder, full_images, full_backgrounds, h, \n",
    "                     n_stars.clamp(max = star_encoder.max_detections))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "seq_tensor = torch.Tensor([i for i in range(log_probs.shape[0])]).type(torch.LongTensor)\n",
    "\n",
    "log_probs_i = log_probs[seq_tensor, _n_stars.clamp(max = star_encoder.max_detections)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_probs_i.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "############################\n",
    "# get loss at map n_stars\n",
    "############################\n",
    "map_n_stars = n_stars.clamp(max = star_encoder.max_detections) # torch.argmax(log_probs, 1)\n",
    "map_is_on = get_is_on_from_n_stars(map_n_stars, star_encoder.max_detections)\n",
    "\n",
    "# sample locations\n",
    "subimage_locs_sampled = torch.sigmoid(sample_normal(logit_loc_mean, logit_loc_log_var)) * \\\n",
    "                        map_is_on.unsqueeze(2).float()\n",
    "\n",
    "# sample fluxes\n",
    "subimage_fluxes_sampled = torch.exp(sample_normal(log_flux_mean, log_flux_log_var)) * \\\n",
    "                    map_is_on.float()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get reconstruction loss\n",
    "_, recon_loss = get_recon_loss(full_images, full_backgrounds, subimage_locs_sampled, subimage_fluxes_sampled,\n",
    "                           star_encoder.tile_coords, \n",
    "                           star_encoder.stamp_slen, \n",
    "                           star_encoder.edge_padding, \n",
    "                           star_dataset.simulator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_kl_prior_term = get_kl_prior_term(logit_loc_mean, logit_loc_log_var).sum(2) \n",
    "fluxes_kl_prior_term = get_kl_prior_term(log_flux_mean, log_flux_log_var)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fluxes_kl_prior_term"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image_stamps, subimage_locs, subimage_fluxes, n_stars, is_on_array = \\\n",
    "    star_encoder.get_image_stamps(images, true_locs, true_fluxes, trim_images=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get reconstruction with the subimage parameters \n",
    "patch_simulator = simulated_datasets_lib.StarSimulator(psf_fit_file, \n",
    "                                                       star_encoder.stamp_slen - 2 * star_encoder.edge_padding, \n",
    "                                                       data_params['sky_intensity'])\n",
    "\n",
    "_n_stars = data_params['max_stars'] * torch.ones(subimage_locs.shape[0]).type(torch.LongTensor)\n",
    "\n",
    "recon_means = patch_simulator.draw_image_from_params(subimage_locs, \n",
    "                                                subimage_fluxes, \n",
    "                                                _n_stars, \n",
    "                                                add_noise = False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(10): \n",
    "    f, axarr = plt.subplots(1, 3, figsize=(16, 6))\n",
    "    indx = int(np.random.choice(image_stamps.shape[0], 1))\n",
    "    \n",
    "    which_nonzero = is_on_array[indx]\n",
    "    \n",
    "    im1 = axarr[0].matshow(image_stamps[indx].squeeze())\n",
    "    patch_slen = star_encoder.stamp_slen - 2 * star_encoder.edge_padding\n",
    "    axarr[0].scatter(subimage_locs[indx, which_nonzero, 1] * (patch_slen - 1), \n",
    "                    subimage_locs[indx, which_nonzero, 0] * (patch_slen - 1))\n",
    "    f.colorbar(im1, ax = axarr[0])\n",
    "    \n",
    "    axarr[0].set_title('n_stars: {}\\n'.format(n_stars[indx]))\n",
    "    \n",
    "    im2 = axarr[1].matshow(recon_means[indx].squeeze())\n",
    "    f.colorbar(im2, ax = axarr[1])\n",
    "    \n",
    "    im3 = axarr[2].matshow(image_stamps[indx].squeeze() - recon_means[indx].squeeze())\n",
    "    f.colorbar(im3, ax = axarr[2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Check my parameters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "background_stamps = backgrounds.mean() # TODO"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image_stamps, subimage_locs, subimage_fluxes, n_stars, is_on_array = \\\n",
    "    star_encoder.get_image_stamps(images, true_locs, true_fluxes, trim_images=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(n_stars)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logit_loc_mean, logit_loc_log_var, \\\n",
    "    log_flux_mean, log_flux_log_var, log_probs = \\\n",
    "        star_encoder(image_stamps, background_stamps, n_stars)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logit_loc_mean.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logit_loc_mean"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_log_probs_all = \\\n",
    "        objectives_lib.get_locs_logprob_all_combs(subimage_locs,\n",
    "                                    logit_loc_mean,\n",
    "                                    logit_loc_log_var)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_log_probs_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flux_log_probs_all = \\\n",
    "        objectives_lib.get_fluxes_logprob_all_combs(subimage_fluxes, \\\n",
    "                                    log_flux_mean, log_flux_log_var)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flux_log_probs_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is_on_array.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import hungarian_alg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_log_probs_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is_on_array.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# is_on_array[is_on_array.float().sum(dim = 1) > star_encoder.max_detections] = 0\n",
    "perm = objectives_lib.run_batch_hungarian_alg_parallel(locs_log_probs_all, is_on_array.type(torch.bool)).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "is_on_array.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_log_probs_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perm.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "locs_log_probs_all.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "objectives_lib._permute_losses_mat(locs_log_probs_all, perm).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "objectives_lib._permute_losses_mat(locs_log_probs_all, perm).shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "objectives_lib.get_encoder_loss(star_encoder, \n",
    "                                images, \n",
    "                                backgrounds, \n",
    "                               true_locs, \n",
    "                               true_fluxes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "objectives_lib.eval_star_encoder_loss(star_encoder, loader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(n_stars)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image = image_stamps; background = 686."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "log_img = torch.log(image - background + 1000)\n",
    "\n",
    "# means = log_img.view(image.shape[0], self.n_bands, -1).mean(-1)\n",
    "# stds = log_img.view(image.shape[0], self.n_bands, -1).std(-1)\n",
    "mins = log_img.view(image.shape[0], 1, -1).min(-1)[0]\n",
    "maxes = log_img.view(image.shape[0], 1, -1).max(-1)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mins[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maxes[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo = (log_img - mins.unsqueeze(-1).unsqueeze(-1)) / (maxes - mins).unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.min(foo[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.max(foo[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo = np.loadtxt('../fits/test_losses')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "foo[:, 6]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_04)",
   "language": "python",
   "name": "pytorch_update"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
